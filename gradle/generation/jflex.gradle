/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import groovy.json.*
import org.apache.commons.codec.digest.DigestUtils

// Add a top-level pseudo-task to which we will attach individual regenerate tasks.

configure(rootProject) {
  configurations {
    jflex
  }

  dependencies {
    jflex "de.jflex:jflex:${scriptDepVersions['jflex']}"
  }
}

configure(project(":lucene:core")) {
  task jflexStandardTokenizerImpl(type: JFlexTask) {
    description "Regenerate StandardTokenizerImpl.java"
    group "generation"

    jflexFile = file('src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex')
    skeleton = file("src/data/jflex/skeleton.disable.buffer.expansion.txt")

    doLast {
      ant.replace(
          file: file('src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.java'),
          encoding: "UTF-8",
          token: "private static final int ZZ_BUFFERSIZE =",
          value: "private int ZZ_BUFFERSIZE ="
      )
    }
  }

  regenerate.dependsOn jflexStandardTokenizerImpl, "tidy"
}

configure(project(":lucene:analysis:common")) {
  task jflexWikipediaTokenizerImpl(type: JFlexTask) {
    description "Regenerate WikipediaTokenizerImpl.java"
    group "generation"

    jflexFile = file('src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerImpl.jflex')
    skeleton = project(":lucene:core").file("src/data/jflex/skeleton.default")
  }

  task jflexClassicTokenizerImpl(type: JFlexTask) {
    description "Regenerate ClassicTokenizerImpl.java"
    group "generation"

    jflexFile = file('src/java/org/apache/lucene/analysis/classic/ClassicTokenizerImpl.jflex')
    skeleton = project(":lucene:core").file("src/data/jflex/skeleton.default")
  }

// incremental task generation - experiment
  Task sourceTask = jflexClassicTokenizerImpl

  Task checksumLoadTask = tasks.create("${sourceTask.name}ChecksumLoad", {
    ext {
      checksumMatch = true
    }

    doFirst {
      // Collect all of task inputs/ outputs.
      FileCollection allFiles = sourceTask.inputs.files + sourceTask.outputs.files
      ext.allFiles = allFiles

      // Compute checksums for root-project relative paths
      Map<File, String> actualChecksums = allFiles.files.collectEntries { file ->
        [
            sourceTask.project.rootDir.relativePath(file),
            file.exists() ? new DigestUtils(DigestUtils.sha1Digest).digestAsHex(file).trim() : "--"
        ]
      }
      ext.actualChecksums = actualChecksums

      // Load any previously written checksums
      ext.checksumsFile = project.file("src/generated/checksums/${sourceTask.name}.json")
      Map<File, String> savedChecksums = [:]
      if (checksumsFile.exists()) {
        savedChecksums = new JsonSlurper().parse(checksumsFile) as Map
      }
      ext.savedChecksums = savedChecksums

      ext.checksumMatch = (savedChecksums.equals(actualChecksums))
    }
  })

  Task checksumSaveTask = tasks.create("${sourceTask.name}ChecksumSave", {
    dependsOn checksumLoadTask

    doFirst {
      File checksumsFile = checksumLoadTask.ext.checksumsFile
      checksumsFile.parentFile.mkdirs()

      // Recompute checksums for root-project relative paths
      Map<File, String> actualChecksums = checksumLoadTask.ext.allFiles.files.collectEntries { file ->
        [
            sourceTask.project.rootDir.relativePath(file),
            new DigestUtils(DigestUtils.sha1Digest).digestAsHex(file).trim()
        ]
      }

      checksumsFile.setText(
          JsonOutput.prettyPrint(JsonOutput.toJson(actualChecksums)), "UTF-8")

      logger.lifecycle("Updated generated file checksums for task ${sourceTask.path}.")
    }
  })

  Task genWrapperTask = tasks.create("${sourceTask.name}Conditional", {
    List<Task> orderedTasks = [checksumLoadTask, sourceTask, tidy, checksumSaveTask]
    dependsOn orderedTasks

    // Hard ordering of dependency execution.
    for (int i = 1; i < orderedTasks.size(); i++) {
      orderedTasks[i].mustRunAfter orderedTasks[i - 1]
    }

    // Conditional execution only if checksum mismatch occurred.
    orderedTasks.each { t ->
      if (t != tidy && t != checksumLoadTask) {
        t.onlyIf { !checksumLoadTask.checksumMatch }
      }
    }

    doFirst {
      if (checksumLoadTask.checksumMatch) {
        logger.lifecycle("Generated file checksums for task ${sourceTask.path} consistent with sources, skipped generation tasks.")
      }
    }
  })
// end

  task jflexUAX29URLEmailTokenizerImpl(type: JFlexTask) {
    description "Regenerate UAX29URLEmailTokenizerImpl.java"
    group "generation"

    jflexFile = file('src/java/org/apache/lucene/analysis/email/UAX29URLEmailTokenizerImpl.jflex')
    skeleton = project(":lucene:core").file("src/data/jflex/skeleton.disable.buffer.expansion.txt")
    heapSize = "12g"

    doFirst {
      logger.lifecycle("Regenerating UAX29URLEmailTokenizerImpl. This may take a long time (and requires ${heapSize} of memory!).")
    }

    doLast {
      ant.replace(
          file: file('src/java/org/apache/lucene/analysis/email/UAX29URLEmailTokenizerImpl.java'),
          encoding: "UTF-8",
          token: "private static final int ZZ_BUFFERSIZE =",
          value: "private int ZZ_BUFFERSIZE ="
      )
    }
  }

  task jflexHTMLStripCharFilter(type: JFlexTask) {
    description "Regenerate HTMLStripCharFilter.java"
    group "generation"

    jflexFile = file('src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex')
    skeleton = project(":lucene:core").file("src/data/jflex/skeleton.default")

    doFirst {
      // Regenerate HTMLCharacterEntities.jflex first.
      def target = file('src/java/org/apache/lucene/analysis/charfilter/HTMLCharacterEntities.jflex')
      quietExec {
        executable = project.externalTool("python3")
        workingDir = target.parentFile
        args += [
            "-B", // don't write any bytecode cache
            "htmlentity.py"
        ]
      }

      project.ant.fixcrlf(
          file: target,
          encoding: "UTF-8",
          eol: "lf"
      )
    }
  }

  regenerate.dependsOn jflexUAX29URLEmailTokenizerImpl,
          jflexHTMLStripCharFilter,
          "jflexClassicTokenizerImplConditional",
          jflexWikipediaTokenizerImpl,
          "tidy"
}

class JFlexTask extends DefaultTask {
  @InputFile
  File jflexFile

  @InputFile
  File skeleton

  @Optional
  String heapSize

  @OutputFile
  File getGeneratedFile() {
    return project.file(jflexFile.absolutePath.replace(".jflex", ".java"))
  }

  JFlexTask() {
    dependsOn(project.rootProject.configurations.jflex)
  }

  @TaskAction
  def generate() {
    if (!jflexFile || !jflexFile.exists()) {
      throw new GradleException("JFlex file does not exist: ${jflexFile}")
    }

    def target = project.file(jflexFile.absolutePath.replace(".jflex", ".java"))

    logger.lifecycle("Recompiling JFlex: ${project.rootDir.relativePath(jflexFile)}")

    project.javaexec {
      classpath {
        project.rootProject.configurations.jflex
      }

      main = "jflex.Main"
      args += [
          "-nobak",
          "--quiet",
          "--encoding", "UTF-8",
      ]

      if (heapSize) {
        maxHeapSize = heapSize
      }

      if (skeleton) {
        args += ["--skel", skeleton.absolutePath]
      }

      args += [
          "-d", target.parentFile.absolutePath,
          jflexFile
      ]
    }

    // Correct line endings for Windows.
    project.ant.fixcrlf(
        file: target,
        encoding: "UTF-8",
        eol: "lf"
    )
  }
}
