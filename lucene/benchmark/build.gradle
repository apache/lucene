/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

plugins {
  id "java"
  id "de.undercouch.download"
}

description = 'System for benchmarking Lucene'

dependencies {  
  implementation project(':lucene:core')

  implementation project(':lucene:analysis:common')
  implementation project(':lucene:facet')
  implementation project(':lucene:highlighter')
  implementation project(':lucene:queries')
  implementation project(':lucene:spatial-extras')
  implementation project(':lucene:queryparser')

  implementation "org.apache.commons:commons-compress"
  implementation "com.ibm.icu:icu4j"
  implementation "org.locationtech.spatial4j:spatial4j"
  implementation("net.sourceforge.nekohtml:nekohtml", {
    exclude module: "xml-apis"
  })

  runtimeOnly project(':lucene:analysis:icu')

  testImplementation project(':lucene:test-framework')
}

ext {
  dataDir = file("data")
}

def tempDir = file("temp")
def workDir = file("work")

task run(type: JavaExec) {
  description "Run a perf test (optional: -PtaskAlg=conf/your-algorithm-file -PmaxHeapSize=1G)"
  main 'org.apache.lucene.benchmark.byTask.Benchmark'
  classpath sourceSets.main.runtimeClasspath
  // allow these to be specified on the CLI via -PtaskAlg=  for example
  args = [propertyOrDefault('taskAlg', 'conf/micro-standard.alg')]

  maxHeapSize = propertyOrDefault('maxHeapSize', '1G')

  String stdOutStr = propertyOrDefault('standardOutput', null)
  if (stdOutStr != null) {
    standardOutput = new File(stdOutStr).newOutputStream()
  }

  debugOptions {
    enabled = false
    port = 5005
    suspend = true
  }
}

// The remaining tasks just get / extract / prepare data

task getEnWiki(type: Download) {
  ext {
    name = "enwiki-20070527-pages-articles.xml"
    src = "https://home.apache.org/~dsmiley/data/${name}.bz2"
    intermediate = file("${dataDir}/${name}.bz2")
    dst = file("${dataDir}/${name}")
  }

  outputs.file ext.dst

  src ext.src
  dest ext.intermediate
  overwrite false
  compress false

  doLast {
    logger.lifecycle("Decompressing ${ext.name}...")
    ant.bunzip2(src: ext.intermediate, dest: ext.dst)
  }
}

task getGeoNames(type: Download) {
  // note: latest data is at: https://download.geonames.org/export/dump/allCountries.zip
  //       and then randomize with: gsort -R -S 1500M file.txt > file_random.txt
  //       and then compress with: bzip2 -9 -k file_random.txt
  ext {
    name = "geonames_20130921_randomOrder_allCountries.txt"
    src = "https://home.apache.org/~dsmiley/data/${name}.bz2"
    intermediate = file("${dataDir}/${name}.bz2")
    dst = file("${dataDir}/${name}")
  }

  outputs.file ext.dst

  src ext.src
  dest ext.intermediate
  overwrite false
  compress false

  doLast {
    logger.lifecycle("Decompressing ${ext.name}...")
    ant.bunzip2(src: ext.intermediate, dest: ext.dst)
  }
}

task getTop100kWikiWordFiles(type: Download) {
  ext {
    name = "top.100k.words.de.en.fr.uk.wikipedia.2009-11"
    src = "https://home.apache.org/~rmuir/wikipedia/${name}.tar.bz2"
    intermediate = file("${dataDir}/${name}.bz2")
    dst = file("${dataDir}/${name}")
  }

  outputs.file ext.dst

  src ext.src
  dest ext.intermediate
  overwrite false
  compress false

  doLast {
    logger.lifecycle("Decompressing ${ext.name}...")
    project.sync {
      from tarTree(ext.intermediate) // defined above. Will decompress on the fly
      into ext.dst
    }
  }
}

task getReuters(type: Download) {
  ext {
    name = "reuters21578"
    // note: there is no HTTPS url and we don't care because this is merely test/perf data
    src = "http://www.daviddlewis.com/resources/testcollections/reuters21578/${name}.tar.gz"
    intermediate = file("${dataDir}/${name}.tar.gz")
    dst = file("${dataDir}/${name}")
  }

  outputs.dir ext.dst

  src ext.src
  dest ext.intermediate
  overwrite false
  compress false

  dependsOn sourceSets.main.runtimeClasspath

  doLast {
    def untarPath = file("$temporaryDir/reuters-untar")

    logger.lifecycle("Decompressing ${ext.name}...")
    project.sync {
      from(tarTree(intermediate)) {
        exclude '*.txt'
      }
      into untarPath
    }

    logger.lifecycle("Extracting ${ext.name} into ${ext.dst}...")
    ext.dst.deleteDir()

    // TODO consider porting ExtractReuters to groovy?
    project.javaexec {
      main = 'org.apache.lucene.benchmark.utils.ExtractReuters'
      classpath = sourceSets.main.runtimeClasspath
      maxHeapSize = '1G'
      args = [untarPath, ext.dst]
    }
  }
}

[getEnWiki, getGeoNames, getTop100kWikiWordFiles, getReuters].each { task ->
  task.group "Data set download"
  task.description "Download the ${task.ext.name} data set."

  task.doFirst {
    logger.lifecycle("Downloading data set ${task.ext.name} from ${task.ext.src} to ${task.ext.dst}...")
  }
}
