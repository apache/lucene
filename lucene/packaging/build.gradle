/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import org.apache.commons.codec.digest.DigestUtils

// This project puts together a "distribution", assembling bits and pieces
// into a binary, source and maven artifacts.

plugins {
    id 'distribution'
    id 'signing'
}

description = 'Lucene distribution packaging'

// Declare all subprojects that should be included in binary distribution.
// By default everything is included, unless explicitly excluded.
def includeInBinaries = project(":lucene").subprojects.findAll {subproject ->
    return !(subproject.path in [
        // Exclude packaging & documentation, not relevant to binary distribution.
        ":lucene:packaging",
        ":lucene:documentation",
        // Exclude parent container project of analysis modules (no artifacts).
        ":lucene:analysis",
        // Exclude native module, which requires manual copying and enabling
        ":lucene:misc:native"
    ])
}

// Generate an sha512 checksum for the given file.
def checksum = { file ->
    String sha512 = new DigestUtils(DigestUtils.sha512Digest).digestAsHex(file).trim()
    // The asterisk signals a binary file, see https://www.gnu.org/software/coreutils/manual/coreutils.html#md5sum-invocation
    new File(file.parent, file.name + ".sha512").write(sha512 + " *" + file.name, "UTF-8")
}

// Create a configuration to each subproject and add dependency.
def binaryArtifactsConf = { Project prj ->
    "dep-binary" + prj.path.replace(':', '-')
}

def allDepsConf = { Project prj ->
    "dep-full" + prj.path.replace(':', '-')
}

configurations {
    docs
}

for (Project includedProject : includeInBinaries) {
    def confBinaries = binaryArtifactsConf(includedProject)
    def confFull = allDepsConf(includedProject)
    configurations.create(confBinaries)
    configurations.create(confFull)
    dependencies { DependencyHandler handler ->
        // Just project binaries.
        handler.add(confBinaries, project(path: includedProject.path, configuration: "packaging"))
        // All project dependencies, including transitive dependencies from the runtime configuration.
        handler.add(confFull, project(path: includedProject.path, configuration: "runtimeElements"), {
            exclude group: "org.apache.lucene"

            // Exclude these from all projects.
            exclude group: "commons-logging"
            exclude group: "org.slf4j"
        })
    }
}

dependencies {
    docs project(path: ':lucene:documentation', configuration: 'site')
}

distributions {
    // The "main" distribution is the binary distribution.
    main {
        distributionBaseName = 'lucene'

        contents {
            // Manually correct posix permissions (matters when packaging on Windows).
            filesMatching(["**/*.sh", "**/*.bat"]) { copy ->
                copy.setMode(0755)
            }

            // Root distribution files; these are cherry-picked manually.
            from(project(':lucene').projectDir, {
                include "CHANGES.txt"
                include "JRE_VERSION_MIGRATION.md"
                include "LICENSE.txt"
                include "licenses/*"
                include "MIGRATE.md"
                include "NOTICE.txt"
                include "README.md"
                include "SYSTEM_REQUIREMENTS.md"
            })

            // A couple more missing README files
            from(project(':lucene:analysis').projectDir) {
                include "README.txt"
                into 'analysis'
            }

            // Copy files from documentation output to 'docs'
            from(configurations.docs, {
                into 'docs'
            })

            // Put included project's binary artifacts under their corresponding subfolders.
            // This needs to be a for-loop instead of projects.each since the "from" could be resolved at the wrong time
            for (Project includedProject : includeInBinaries) {
                def basePath = includedProject.path.replaceFirst("^:lucene:", "").replace(':', '/')
                def confBinaries = configurations.findByName(binaryArtifactsConf(includedProject))
                def confFull = configurations.findByName(allDepsConf(includedProject))

                from(confBinaries, {
                    into basePath
                })
                from(confFull, {
                    into "${basePath}/lib"
                    // Manually exclude the project's main artifact. Don't know if there is any better way to do this.
                    exclude "lucene-*"
                })
            }
        }
    }
}

distZip {
    doLast {
        outputs.files.files.each checksum
    }
}

distTar {
    compression = Compression.GZIP
    doLast {
        outputs.files.files.each checksum
    }
}

installDist {
    doLast {
        logger.lifecycle "Distribution assembled under: ${destinationDir}"
    }
}

// Add common packaging artifacts.
configure(project(":lucene").subprojects) {
    plugins.withType(JavaPlugin) {
        ext {
            packagingDir = file("${buildDir}/packaging")
        }

        configurations {
            packaging
        }

        task assemblePackaging(type: Sync) {
            from(projectDir, {
                include "README.*"
            })

            from(tasks.findByName("jar"))

            into packagingDir
        }

        artifacts {
            packaging packagingDir, {
                builtBy assemblePackaging
            }
        }
    }
}

// Add launch scripts for Luke.
configure(project(":lucene:luke")) {
    plugins.withType(JavaPlugin) {
        assemblePackaging {
            from("${projectDir}/bin", {
            })
        }
    }
}

configurations {
  luceneTgz
  luceneZip
}

artifacts {
  luceneTgz(distTar)
  luceneZip(distZip)
}

// Source distribution using git export
task assembleSourceDist() {
    def sourceTarFile = file("${buildDir}/distributions/lucene-${version}-src.tgz")
    outputs.file sourceTarFile

    doFirst {
        quietExec {
            executable = project.externalTool("git")
            workingDir = project.rootDir

            args += [
                    "archive",
                    "--format", "tgz",
                    "--prefix", "lucene-${version}/",
                    "--output", sourceTarFile,
                    "HEAD"
            ]
        }

        checksum(sourceTarFile)
    }
}

assembleDist.dependsOn assembleSourceDist

// NOTE: we don't use the convinence DSL of the 'signing' extension to define our 'Sign' tasks because
// that (by default) adds our signature files to the 'archives' configuration -- which is what
// assemble & installDist try to copy/sync, so they wouldn't work w/o GPG installed (which would be bad).
//
// We also want to hook in our own property check dependency since the default error message from Sign task
// refers to the wrong (internal only) property name ("signatory.keyId")
signing {
  useGpgCmd() // so gpg-agent can be used
}

task failUnlessGpgKeyProperty {
  // placeholder that can be depended on by any task needing GPG key which will 'fail fast' if it's not set.
  def propName = 'signing.gnupg.keyName'

  // This explicitly checks the taskGraph (instead of a simple 'doFirst') so it can fail the user's gradle
  // invocation immediately before any unrelated build tasks may run in parallel
  if ( ! project.hasProperty(propName) ) {
    gradle.taskGraph.whenReady { graph ->
      if ( graph.hasTask(failUnlessGpgKeyProperty) ) {
        // TODO: it would be really nice if taskGraph was an actual graph and we could report what tasks in (transitive) depend on us
        throw new GradleException("'$propName' property must be set for GPG signing, please see help/gpgSigning.txt")
      }
    }
  }
}

task signDistTar(type: Sign) {
  dependsOn failUnlessGpgKeyProperty
  sign configurations.luceneTgz
}

task signDistZip(type: Sign) {
  dependsOn failUnlessGpgKeyProperty
  sign configurations.luceneZip
}

task signSourceDistTar(type: Sign) {
    dependsOn failUnlessGpgKeyProperty, assembleSourceDist
    sign assembleSourceDist.outputs.files.singleFile
}

task signDist {
  group = 'Distribution'
  description = 'GPG Signs the main distributions'
  dependsOn signDistTar, signDistZip, signSourceDistTar
}

// Collect changes rendered to HTML.

configurations {
    changesHtml
}

dependencies {
    changesHtml project(path: ":lucene:documentation", configuration: "changesHtml")
}

task syncChanges(type: Sync) {
    from(configurations.changesHtml, {
        into "/"
    })

    into file("${buildDir}/distributions/changes")
}
assembleDist.dependsOn syncChanges

// Collect signed JARs (publications).

def mavenDistDir = file("${buildDir}/distributions/maven")
task collectSignedMavenArtifacts() {
    doLast {
        logger.lifecycle "Local maven artifacts (poms, jars) created at: ${mavenLocalDir}"
    }
}

task wipeMavenDist(type: Delete) {
    delete mavenDistDir
}

configure(rootProject.subprojects.findAll { it.path in rootProject.published }) {
    plugins.withType(PublishingPlugin) {
        publishing {
            repositories {
                maven {
                    name = 'dist'
                    url = mavenDistDir
                }
            }
        }

        tasks.matching { it.name == "publishJarsPublicationToDistRepository" }.all { task ->
            // Clean local repo prior to republishing artifacts.
            task.dependsOn wipeMavenDist
            collectSignedMavenArtifacts.dependsOn task
        }
    }
}
assembleDist.dependsOn collectSignedMavenArtifacts
